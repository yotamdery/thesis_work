{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## This notebook produces cases per year for the benchmark with info simulation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import pickle\n",
    "import datetime, random, copy\n",
    "import sys, os, tqdm\n",
    "\n",
    "import SEIR_full as mdl\n",
    "import SEIR_full.model as mdl\n",
    "import SEIR_full.calibration as mdl\n",
    "from SEIR_full.indices import *\n",
    "from SEIR_full.utils import *\n",
    "from SEIR_full.parameters import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Fixing the ranges of the uncertainty factors that we're interested in:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Creating a list of tuples, each tuple is a realization of randomly picked values for the factors that we change every iteration of the simulation\n",
    "np.random.seed(44)\n",
    "list_of_tuples = []\n",
    "for i in range(1000):\n",
    "    booster_eff = round(np.random.uniform(low=29.5001, high=95.5)) / 100     # Discrete uniform dist, booster_efficiency ~ U(30, 95), Updated in the model's object\n",
    "    inv_level = round(np.random.uniform(low=9.5001, high=20.5)) / 100       # Discrete uniform dist, booster_efficiency ~ U(10, 20), Updated in the simulation's settings\n",
    "    hosp_proba_scalar = round(np.random.uniform(low=0.8, high=1.2), 2)      # Continuous uniform dist, booster_efficiency ~ U(0.8, 1.2), Updated in the model's object\n",
    "    years_for_model_run = round(np.random.uniform(low=.5001, high=5.5))         # Discrete uniform dist, booster_efficiency ~ U(3, 10), Updated in the simulation's settings\n",
    "    list_of_tuples.append((booster_eff, inv_level, hosp_proba_scalar, years_for_model_run))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Fixing the static settings for all runs of the big loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "## DEFINING STATIC SETTINGS (INDEPENDENT IN THE DYNAMIC FACTORS) FOR THE SIMULATION RUN\n",
    "# Short path for the data directory\n",
    "DATA_DIR = r'/Users/yotamdery/Old_Desktop/git/SEIR_model_COVID-main/Data'\n",
    "# Reading the indices of the model - adding an hint to declare it's from type Indices!\n",
    "with(open(DATA_DIR + '/parameters/indices.pickle', 'rb')) as openfile:\n",
    "    ind:Indices = pickle.load(openfile)\n",
    "\n",
    "# Vaccination priority queue:\n",
    "vaccination_pq = [('High', '60+'), ('High', '30-59'), ('High', '10-29'), ('High', '5-9'),\n",
    "                   ('Low', '60+'), ('Low', '30-59'), ('Low', '10-29'), ('Low', '5-9')]\n",
    "\n",
    "# Reading the neutralized vectors:\n",
    "# Alpha variant vector\n",
    "with open(DATA_DIR + '/parameters/neutralized_alpha_variant_vec.pickle', 'rb') as pickle_in:\n",
    "\tneutralized_alpha_variant_vec = pickle.load(pickle_in)\n",
    "\n",
    "# Delta variant vector\n",
    "with open(DATA_DIR + '/parameters/neutralized_delta_variant_vec.pickle', 'rb') as pickle_in:\n",
    "\tneutralized_delta_variant_vec = pickle.load(pickle_in)\n",
    "\n",
    "# Beta_lockdown vector\n",
    "with open(DATA_DIR + '/parameters/neutralized_lockdown_vec.pickle', 'rb') as pickle_in:\n",
    "\tneutralized_lockdown_vec = pickle.load(pickle_in)\n",
    "\n",
    "# Beta_school vector\n",
    "with open(DATA_DIR + '/parameters/neutralized_school_vec.pickle', 'rb') as pickle_in:\n",
    "\tneutralized_school_vec = pickle.load(pickle_in)\n",
    "\n",
    "# Isolation morbidity ratio vector\n",
    "with open(DATA_DIR + '/parameters/neutralized_isolation_morbidity_ratio_vector.pickle', 'rb') as pickle_in:\n",
    "\tneutralized_isolation_morbidity_ratio_vector = pickle.load(pickle_in)\n",
    "\n",
    "# zero vector to remove any transition from V_2 and S_2 to V_3\n",
    "with open(DATA_DIR + '/parameters/neutralized_transition_rate_to_V_3.pickle', 'rb') as pickle_in:\n",
    "\tneutralized_transition_vector = pickle.load(pickle_in)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Utils functions:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Getting the reported unreported ratio\n",
    "def get_reported_unreported_ratio(scen):\n",
    "    if scen == 'Scenario3':\n",
    "        reported = 1\n",
    "        unreported = 3\n",
    "        reported_unreported = unreported / (reported + unreported)\n",
    "    return reported_unreported\n",
    "\n",
    "def risk_age_groups_mapping(wanted_mapping: tuple):\n",
    "    \"\"\" This function gets a wanted mapping (4 examined age groups to 9 original model's age groups or vice versa),\n",
    "    and returns a dictionary consist of the wanted mapping\n",
    "    \"\"\"\n",
    "    age_groups_mapping_dict = {}\n",
    "    # If the wanted mapping is 4 examined age groups to 9 original model's age groups:\n",
    "    if wanted_mapping == ('High', '4-to-9'):\n",
    "        age_groups_mapping_dict[('High', '5-9')] = [('High', '5-9')]\n",
    "        age_groups_mapping_dict[('High', '10-29')] = [('High', '10-19'), ('High', '20-29')]\n",
    "        age_groups_mapping_dict[('High', '30-59')] = [('High','30-39'), ('High','40-49'), ('High','50-59')]\n",
    "        age_groups_mapping_dict[('High', '60+')] = [('High', '60-69'), ('High', '70+')]\n",
    "\n",
    "    elif wanted_mapping == ('Low', '4-to-9'):\n",
    "        age_groups_mapping_dict[('Low', '5-9')] = [('Low', '5-9')]\n",
    "        age_groups_mapping_dict[('Low', '10-29')] = [('Low', '10-19'), ('Low', '20-29')]\n",
    "        age_groups_mapping_dict[('Low', '30-59')] = [('Low','30-39'), ('Low','40-49'), ('Low','50-59')]\n",
    "        age_groups_mapping_dict[('Low', '60+')] = [('Low', '60-69'), ('Low', '70+')]\n",
    "\n",
    "    # If the wanted mapping is 9 original model's age groups to 4 examined age groups:\n",
    "    elif wanted_mapping == ('High', '9-to-4'):\n",
    "        age_groups_mapping_dict[('High', '0-4')] = np.nan     # There's no corresponding age group among the 4 examined age-groups\n",
    "        age_groups_mapping_dict[('High', '5-9')] = ('High', '5-9')\n",
    "        age_groups_mapping_dict[('High', '10-19')] = ('High', '10-29')\n",
    "        age_groups_mapping_dict[('High', '20-29')] = ('High', '10-29')\n",
    "        age_groups_mapping_dict[('High', '30-39')] = ('High', '30-59')\n",
    "        age_groups_mapping_dict[('High', '40-49')] = ('High', '30-59')\n",
    "        age_groups_mapping_dict[('High', '50-59')] = ('High', '30-59')\n",
    "        age_groups_mapping_dict[('High', '60-69')] = ('High', '60+')\n",
    "        age_groups_mapping_dict[('High', '70+')] = ('High', '60+')\n",
    "\n",
    "    else:\n",
    "        age_groups_mapping_dict[('low', '0-4')] = np.nan     # There's no corresponding age group among the 4 examined age-groups\n",
    "        age_groups_mapping_dict[('low', '5-9')] = ('low', '5-9')\n",
    "        age_groups_mapping_dict[('low', '10-19')] = ('low', '10-29')\n",
    "        age_groups_mapping_dict[('low', '20-29')] = ('low', '10-29')\n",
    "        age_groups_mapping_dict[('low', '30-39')] = ('low', '30-59')\n",
    "        age_groups_mapping_dict[('low', '40-49')] = ('low', '30-59')\n",
    "        age_groups_mapping_dict[('low', '50-59')] = ('low', '30-59')\n",
    "        age_groups_mapping_dict[('low', '60-69')] = ('low', '60+')\n",
    "        age_groups_mapping_dict[('low', '70+')] = ('low', '60+')\n",
    "\n",
    "    return age_groups_mapping_dict\n",
    "\n",
    "def get_wanted_df(wanted_age_group):\n",
    "\t\"\"\" Gets the age-groups that we want to address our calculations to, and returns a sub-Dataframe containing only the relevant columns (the wanted age-groups columns)\"\"\"\n",
    "\t# Reading the pop per county file:\n",
    "\tcounty_pop = pd.read_csv(DATA_DIR + '/division_choice/30/population_per_county_age-group.csv')\n",
    "\t# Initializing the list with the county column, that will be picked anyway\n",
    "\twanted_columns = [county_pop.columns[0]]\n",
    "\t# Splitting the given age_group, creating list of integers. try-expect block to catch the 60+ column as well:\n",
    "\ttry:\n",
    "\t\twanted_age_group_splitted = list(map(int, wanted_age_group.split('-')))\n",
    "\texcept ValueError:\n",
    "\t\twanted_age_group_splitted = [60, 70]  # In order to pass the logic condition successfully\n",
    "\n",
    "\t# Iterating on the columns of the file and performing the condition logic:\n",
    "\tfor col in county_pop.columns[1:]:\n",
    "\t\t# Splitting the current column of the file. try-expect block to catch the 70+ column as well:\n",
    "\t\ttry:\n",
    "\t\t\tages_as_list = list(map(int, col.split('_')[1].split('-')))\n",
    "\t\texcept ValueError:\n",
    "\t\t\tages_as_list = [70]\n",
    "\t\t# If these conditions are met, take this column to be in the sub-df\n",
    "\t\tif ages_as_list[0] >= min(wanted_age_group_splitted) and ages_as_list[0] <= max(wanted_age_group_splitted):\n",
    "\t\t\twanted_columns.append(col)\n",
    "\n",
    "\treturn county_pop[wanted_columns]\n",
    "\n",
    "# Gets a dictionary to reduce (lambda, V_2 or S_2) and reduce its cardinality to consist only the relevant age-groups\n",
    "def calc_sub_dict(dict_to_reduce: dict, wanted_age_group: str):\n",
    "    sub_dict = {}\n",
    "    # Splitting the given age_group, creating list of integers. try-expect block to catch the 60+ group as well (if wanted):\n",
    "    try:\n",
    "        wanted_age_group_splitted = list(map(int, wanted_age_group.split('-')))\n",
    "    except ValueError:\n",
    "        wanted_age_group_splitted = [60, 70]    # In order to pass the logic condition successfully\n",
    "\n",
    "    for key, val in dict_to_reduce.items():\n",
    "        # Splitting the age group part of the key. try-expect block to catch the 70+ column from the file as well:\n",
    "        try:\n",
    "            if isinstance(key, str):   # If the dict_to_reduce keys are only on the age level\n",
    "                ages_as_list = list(map(int, key.split('-')))\n",
    "            elif isinstance(key, tuple):    # If the dict_to_reduce keys are on the region&age level (as lambda_t does) - take the second element (the age)\n",
    "                ages_as_list = list(map(int, key[1].split('-')))\n",
    "        except ValueError:\n",
    "            ages_as_list = [70]\n",
    "        # If these conditions are met, take this key-value pair to be in the sub-dict\n",
    "        if ages_as_list[0] >= min(wanted_age_group_splitted) and ages_as_list[0] <= max(wanted_age_group_splitted):\n",
    "            sub_dict[key] = val    # Converting from ndarray to float\n",
    "\n",
    "    return sub_dict\n",
    "\n",
    "def get_indexes_risk_age_combination(risk_age_group: tuple):\n",
    "    \"\"\"This function gets a tuple of (risk, 4_age_group) and returns the indexes of that combination as they are in the original model (including transformation to the 9 original age groups\n",
    "    e.g.: for ('High', '10-29'), returns the indexes for ('High', '10-19') + ('High', '20-29') \"\"\"\n",
    "    # Initializing the result list and the age groups mapper:\n",
    "    indexes_list_of_lists = []\n",
    "    four_to_nine_age_map = risk_age_groups_mapping((risk_age_group[0], '4-to-9'))\n",
    "    for val in four_to_nine_age_map[risk_age_group]:\n",
    "            indexes_list_of_lists.append(ind.risk_age_dict[val])\n",
    "    # Merging the list of lists to one list:\n",
    "    risk_indexes_list = [item for sublist in indexes_list_of_lists for item in sublist]\n",
    "    return sorted(risk_indexes_list)\n",
    "\n",
    "# Gets the compartment to aggregate, and returns the same compartment, stratified by the original age-groups\n",
    "def calc_aggregated_compartment_by_age_risk(compartment: np.array):\n",
    "    compartment_dict = {}\n",
    "    for risk_age in ind.risk_age_dict.keys():\n",
    "        compartment_dict[risk_age] = float(compartment[:, ind.risk_age_dict[risk_age]].sum(axis=1))\n",
    "    return compartment_dict\n",
    "\n",
    "# Gets the compartment dictionary (the compartment stratified by the old age-groups), and aggregates the compartment to the wanted age-group by returning a dict (e.g agg. V_2 for age group 30-59, using the sub-age-groups 30-39, 40-49, 50-59)\n",
    "def compartment_by_4_age_groups(compartment: dict, target_risk_age_group: tuple):\n",
    "    # Initiate the wanted mapping:\n",
    "    four_to_nine_age_map = risk_age_groups_mapping((target_risk_age_group[0], '4-to-9'))\n",
    "    # Initiate result dict to return:\n",
    "    agg_risk_4_groups_dict = {}\n",
    "    for risk_4_age_group in four_to_nine_age_map.keys():     # Iterating on each combination of (risk, 9 age-groups):\n",
    "        agg_risk_4_groups_dict[risk_4_age_group] = 0\n",
    "    # Performing the aggregation to the new dict - (risk, 4 age groups):\n",
    "    for key, val in four_to_nine_age_map.items():\n",
    "        for tup in val:\n",
    "            agg_risk_4_groups_dict[key] += compartment[tup]\n",
    "\n",
    "    return agg_risk_4_groups_dict\n",
    "\n",
    "def calc_comp_prop_for_age_risk(comp: str, curr_res_mdl_1_ml: dict, target_risk_age_group: tuple):\n",
    "    \"\"\"This function gets the target compartment and the current predictions of the current model,\n",
    "    and returns the compartment aggregated by the wanted combination of (age-group, risk)\"\"\"\n",
    "    # Getting the last day of the compartment:\n",
    "    comp_last_day = np.reshape(curr_res_mdl_1_ml[comp][-1, :], newshape=(1,540))\n",
    "    # Aggregate the compartment by (9 age groups, risk):\n",
    "    comp_agg_9_age_groups_risk = calc_aggregated_compartment_by_age_risk(comp_last_day)\n",
    "    # Aggregate the compartment by (4 age groups, risk):\n",
    "    comp_agg_4_age_groups_risk = compartment_by_4_age_groups(comp_agg_9_age_groups_risk, target_risk_age_group)\n",
    "    # Gets the relevant age group out of the 4 age groups, and summing on it to get the final proportion:\n",
    "    return comp_agg_4_age_groups_risk[target_risk_age_group]\n",
    "\n",
    "def update_compartment(curr_res_mdl_1_ml: dict, compartment: str, updated_array: np.array):\n",
    "    \"\"\"This function gets the current models' predictions, the compartment to update and the updated array, and updates the model object with the updated array\"\"\"\n",
    "    # Initiate settings:\n",
    "    curr_res_mdl_1_ml[compartment][-1] = updated_array\n",
    "    comp_as_list = []\n",
    "    # Changing the updated arrays to be lists of arrays (to allow the update of the model object):\n",
    "    for element in curr_res_mdl_1_ml[compartment]:\n",
    "        comp_as_list.append(element)\n",
    "\n",
    "    # Performing the proper model update\n",
    "    curr_res_mdl_1_ml.update({\n",
    "        compartment : comp_as_list\n",
    "    })\n",
    "\n",
    "# Defining the model - initializing it for t=0:\n",
    "def defining_model(scen):\n",
    "    model_1_ml_ = mdl.Model_behave(\n",
    "    ind= ind,\n",
    "    beta_j= cal_parameters[scen]['beta_j'],\n",
    "    beta_activity= cal_parameters[scen]['beta_activity'],\n",
    "    beta_school= cal_parameters[scen]['beta school'],\n",
    "    scen= scen\n",
    "    )\n",
    "    # Predicting without an assignment (there's no need for that)\n",
    "    model_1_ml_.predict(\n",
    "        days_in_season= 529,    # Num of days between 15/05/20 - 25/10/21\n",
    "        shifting_12_days= True\n",
    "    )\n",
    "    # Updating the vectors to be able to run the model furthermore:\n",
    "    model_1_ml_.update({\n",
    "        'alpha_variant_vec':  neutralized_alpha_variant_vec,\n",
    "        'delta_variant_vec': neutralized_delta_variant_vec,\n",
    "        'isolation_morbidity_ratio_vector': neutralized_isolation_morbidity_ratio_vector,\n",
    "        'is_lockdown': neutralized_lockdown_vec,\n",
    "        'is_school': neutralized_school_vec,\n",
    "        'v2_to_v3_transition_t' : neutralized_transition_vector,\n",
    "        's_2_to_v3_transition_t' : neutralized_transition_vector\n",
    "    })\n",
    "    return model_1_ml_\n",
    "\n",
    "# Update model for current variables of uncertainty:\n",
    "def update_models_object(mdl_1_ml: mdl.Model_behave, realization: tuple):\n",
    "    new_rho = mdl_1_ml.rho * realization[2]\n",
    "    mdl_1_ml.update({\n",
    "        'booster_efficiency': realization[0],\n",
    "        'rho': new_rho\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### calculating the transferring proportion:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def calc_trans_prop(vaccination_pq_: list, curr_res_mdl_1_ml: dict, curr_inv_: float):\n",
    "    # Initializing the accumulated amount used and the priority queue:\n",
    "    curr_inventory_used = 0\n",
    "    vaccination_pq_copy = vaccination_pq_.copy()\n",
    "    # Saving the combinations that we will vaccinate:\n",
    "    vaccinated_que_ = []\n",
    "    # Iterating until we cross the prior inventory level:\n",
    "    while (curr_inventory_used <= curr_inv_):\n",
    "        # Getting the current combination of (age_group, risk) from the pq:\n",
    "        current_risk_age = vaccination_pq_copy.pop(0)\n",
    "        # Getting the correspondent reported/unreported ratio for the Scenario:\n",
    "        #reported_unreported = get_reported_unreported_ratio('Scenario3')\n",
    "        # Getting V2_j,r, S2_j,r proportions:\n",
    "        S_2_age_risk, V_2_age_risk = calc_comp_prop_for_age_risk('S_2', curr_res_mdl_1_ml,current_risk_age), \\\n",
    "                                     calc_comp_prop_for_age_risk('V_2', curr_res_mdl_1_ml,current_risk_age)\n",
    "\n",
    "        # Calculating the formula for num of needed vaccines:\n",
    "        count_vaccines_in_use = (S_2_age_risk + V_2_age_risk) * pop_israel\n",
    "        # Updating the accumulated used vaccines:\n",
    "        curr_inventory_used += count_vaccines_in_use\n",
    "        # Updating the vaccinated_que:\n",
    "        vaccinated_que_.append(current_risk_age)\n",
    "\n",
    "    final_trans_prop = curr_inv_ / curr_inventory_used\n",
    "    return final_trans_prop, vaccinated_que_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vaccinating in booster dose:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "### Vaccinating in booster (moving from S_2 and V_2 to V_3, including the model update):\n",
    "def vaccinate(trans_prop_: float, curr_res_mdl_1_ml: dict, vaccination_que: list):\n",
    "    ## initialize settings:\n",
    "    vaccination_que_copy = vaccination_que.copy()\n",
    "    trans_prop_copy = trans_prop_\n",
    "    reported_unreported = get_reported_unreported_ratio('Scenario3')\n",
    "    # Getting the last day of the compartments and V_3, saving it to a dictionary:\n",
    "    last_day_dict = {'S_2_last_day': np.reshape(curr_res_mdl_1_ml['S_2'][-1, :], newshape=(540) ),\n",
    "                     'V_2_last_day': np.reshape(curr_res_mdl_1_ml['V_2'][-1, :], newshape=(540) ),\n",
    "                     'V_3_last_day': np.reshape(curr_res_mdl_1_ml['V_3'][-1, :], newshape=(540) ),\n",
    "                    }\n",
    "    # Iterating over the combinations of (risk, age_group) that we need to vaccinate, and moving the population, and updating the model:\n",
    "    for curr_risk_age in vaccination_que_copy:\n",
    "        # Getting the relevant indexes to operate in the correspondent locations of the compartment:\n",
    "        curr_risk_age_indexes = get_indexes_risk_age_combination(curr_risk_age)\n",
    "\n",
    "        ## Vaccinating from S_2 to V_3\n",
    "        S_2_last_day_updated, V_3_last_day_updated = vaccinating_from_V_2_S_2(last_day_dict['V_3_last_day'], last_day_dict['S_2_last_day'], trans_prop_copy, curr_risk_age_indexes)\n",
    "        # updating the results:\n",
    "        last_day_dict['V_3_last_day'], last_day_dict['S_2_last_day'] = V_3_last_day_updated, S_2_last_day_updated\n",
    "\n",
    "        ## Vaccinating from V_2 to V_3\n",
    "        V_2_last_day_updated, V_3_last_day_updated = vaccinating_from_V_2_S_2(last_day_dict['V_3_last_day'], last_day_dict['V_2_last_day'], trans_prop_copy, curr_risk_age_indexes)\n",
    "        # updating the results:\n",
    "        last_day_dict['V_3_last_day'], last_day_dict['V_2_last_day'] = V_3_last_day_updated, V_2_last_day_updated\n",
    "\n",
    "    update_compartment(curr_res_mdl_1_ml, 'V_2', last_day_dict['V_2_last_day'])\n",
    "    update_compartment(curr_res_mdl_1_ml, 'S_2', last_day_dict['S_2_last_day'])\n",
    "    update_compartment(curr_res_mdl_1_ml, 'V_3', last_day_dict['V_3_last_day'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Main - 1000 iterations of the Sim:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# A list to hold 1000 realizations of cases per year:\n",
    "cases_per_year_list = []\n",
    "\n",
    "# Big loop run:\n",
    "for tup in tqdm.tqdm(list_of_tuples, desc= 'tqdm() Progress Bar'):\n",
    "    # Initializing the model's object (and its predictions) to t=0:\n",
    "    model_1_ml = defining_model('Scenario3')\n",
    "    # Settings:\n",
    "    update_models_object(model_1_ml, tup)       # Updating the v3_efficiency and the proba for hosp\n",
    "    inv_level = tup[1] * pop_israel             # Updating the inventory level\n",
    "    years_for_model_run = tup[3]                # Updating the years for the model to run for\n",
    "\n",
    "    # Running the model for X years, in 6 months resolution\n",
    "    for i in range(years_for_model_run*2):\n",
    "        # Running until the vaccination month:\n",
    "        for j in range(1):\n",
    "            res_mdl_1_ml = model_1_ml.predict(\n",
    "                            days_in_season= 30,\n",
    "                            continuous_predict= True\n",
    "                            )\n",
    "            # Getting the proportion of transition, and the combinations that we vaccinate:\n",
    "            trans_prop, vaccinated_que = calc_trans_prop(vaccination_pq, res_mdl_1_ml, inv_level)\n",
    "            # Vaccinating (including the model update):\n",
    "            vaccinate(trans_prop, res_mdl_1_ml, vaccinated_que)\n",
    "\n",
    "        # Running the model until the end of the current \"single\" run (half a year)\n",
    "        for k in range(5):\n",
    "            res_mdl_1_ml = model_1_ml.predict(\n",
    "                days_in_season= 30,\n",
    "                continuous_predict= True\n",
    "            )\n",
    "\n",
    "    ## Calculating the cases per year index for every measurement:\n",
    "    tot_new_Is = np.add(res_mdl_1_ml['new_Is_1'].sum(axis=1) * pop_israel, res_mdl_1_ml['new_Is_2'].sum(axis=1) * pop_israel)\n",
    "    tot_new_H = np.add(res_mdl_1_ml['new_H_1'].sum(axis=1) * pop_israel, res_mdl_1_ml['new_H_2'].sum(axis=1) * pop_israel)\n",
    "    # Transferring to cumulative sum:\n",
    "    cumsum_tot_new_Is, cumsum_tot_new_H = np.cumsum(tot_new_Is), np.cumsum(tot_new_H)\n",
    "    # Performing the calculation itself:\n",
    "    cases_per_year_new_Is, cases_per_year_new_H = (cumsum_tot_new_Is[-1] - cumsum_tot_new_Is[528]) / years_for_model_run, (cumsum_tot_new_H[-1] - cumsum_tot_new_H[528]) / years_for_model_run\n",
    "    cases_per_year_list.append((cases_per_year_new_Is, cases_per_year_new_H))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cases_per_year_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('cases_per_year_list.pickle', 'wb') as handle:\n",
    "    pickle.dump(cases_per_year_list, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}