{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import itertools\n",
    "import warnings \n",
    "warnings.simplefilter('ignore')\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display format\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files:\n",
    "xxx = pd.read_excel(r'/Users/yotamdery/Old Desktop/git/SEIR_model_covid_yotams/Data/division_choice/30/taz2cell.xlsx',engine='openpyxl') \n",
    "mapping_250_30_string = pd.read_excel(r'/Users/yotamdery/Old Desktop/git/Covid_data_investigation/cell250_to_cell30.xlsx',engine='openpyxl')\n",
    "mapping_30str_to_30int = mapping_taz_250 = pd.read_excel(r'county_int_2name_county_string.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_to_30_string = xxx.merge(mapping_250_30_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_to_30_int = taz_to_30_string.merge(mapping_30str_to_30int, left_on= '30_county', right_on= 'county_string_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taz_id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>30_county</th>\n",
       "      <th>county_id</th>\n",
       "      <th>cell_name</th>\n",
       "      <th>county_string_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>1216</td>\n",
       "      <td>2000001</td>\n",
       "      <td>11</td>\n",
       "      <td>1100</td>\n",
       "      <td>Jerusalem  generall w/o bet shemesh</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>1139</td>\n",
       "      <td>2000001</td>\n",
       "      <td>11</td>\n",
       "      <td>1100</td>\n",
       "      <td>Jerusalem  generall w/o bet shemesh</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>1140</td>\n",
       "      <td>2000001</td>\n",
       "      <td>11</td>\n",
       "      <td>1100</td>\n",
       "      <td>Jerusalem  generall w/o bet shemesh</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>1141</td>\n",
       "      <td>2000001</td>\n",
       "      <td>11</td>\n",
       "      <td>1100</td>\n",
       "      <td>Jerusalem  generall w/o bet shemesh</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>1142</td>\n",
       "      <td>2000001</td>\n",
       "      <td>11</td>\n",
       "      <td>1100</td>\n",
       "      <td>Jerusalem  generall w/o bet shemesh</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1325</td>\n",
       "      <td>2000250</td>\n",
       "      <td>71</td>\n",
       "      <td>7100</td>\n",
       "      <td>Shomron generall</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1326</td>\n",
       "      <td>2000250</td>\n",
       "      <td>71</td>\n",
       "      <td>7100</td>\n",
       "      <td>Shomron generall</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>1337</td>\n",
       "      <td>2000250</td>\n",
       "      <td>71</td>\n",
       "      <td>7100</td>\n",
       "      <td>Shomron generall</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1323</td>\n",
       "      <td>2000250</td>\n",
       "      <td>71</td>\n",
       "      <td>7100</td>\n",
       "      <td>Shomron generall</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1321</td>\n",
       "      <td>2000250</td>\n",
       "      <td>71</td>\n",
       "      <td>7100</td>\n",
       "      <td>Shomron generall</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2630 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      taz_id  cell_id 30_county  county_id  \\\n",
       "1206    1216  2000001        11       1100   \n",
       "1201    1139  2000001        11       1100   \n",
       "1202    1140  2000001        11       1100   \n",
       "1203    1141  2000001        11       1100   \n",
       "1204    1142  2000001        11       1100   \n",
       "...      ...      ...       ...        ...   \n",
       "1458    1325  2000250        71       7100   \n",
       "1459    1326  2000250        71       7100   \n",
       "1461    1337  2000250        71       7100   \n",
       "1456    1323  2000250        71       7100   \n",
       "1454    1321  2000250        71       7100   \n",
       "\n",
       "                                cell_name county_string_id  \n",
       "1206  Jerusalem  generall w/o bet shemesh               11  \n",
       "1201  Jerusalem  generall w/o bet shemesh               11  \n",
       "1202  Jerusalem  generall w/o bet shemesh               11  \n",
       "1203  Jerusalem  generall w/o bet shemesh               11  \n",
       "1204  Jerusalem  generall w/o bet shemesh               11  \n",
       "...                                   ...              ...  \n",
       "1458                     Shomron generall               71  \n",
       "1459                     Shomron generall               71  \n",
       "1461                     Shomron generall               71  \n",
       "1456                     Shomron generall               71  \n",
       "1454                     Shomron generall               71  \n",
       "\n",
       "[2630 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taz_to_30_int.sort_values('cell_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mapping = taz_to_30_int.drop('county_string_id', axis= 1).sort_values('taz_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mapping.to_excel('taz_to_250_to_county_id.xlsx', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Shahaf's pickle file - aggregate every df to be 30 counties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shahafs_pickle = pd.read_pickle(r'../250/mat_macro_model_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('no_work', 0), ('no_work', 1), ('no_work', 2), ('no_100_meters', 0), ('no_100_meters', 1), ('no_100_meters', 2), ('no_bb', 0), ('no_bb', 1), ('no_bb', 2), ('routine', 0), ('routine', 1), ('routine', 2), ('no_school', 0), ('no_school', 1), ('no_school', 2), ('full_lockdown', 0), ('full_lockdown', 1), ('full_lockdown', 2), ('release', 0), ('release', 1), ('release', 2), ('back2routine', 0), ('back2routine', 1), ('back2routine', 2)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shahafs_pickle.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000001</th>\n",
       "      <th>2000002</th>\n",
       "      <th>2000003</th>\n",
       "      <th>2000004</th>\n",
       "      <th>2000005</th>\n",
       "      <th>2000006</th>\n",
       "      <th>2000007</th>\n",
       "      <th>2000008</th>\n",
       "      <th>2000009</th>\n",
       "      <th>2000010</th>\n",
       "      <th>...</th>\n",
       "      <th>2000241</th>\n",
       "      <th>2000242</th>\n",
       "      <th>2000243</th>\n",
       "      <th>2000244</th>\n",
       "      <th>2000245</th>\n",
       "      <th>2000246</th>\n",
       "      <th>2000247</th>\n",
       "      <th>2000248</th>\n",
       "      <th>2000249</th>\n",
       "      <th>2000250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000001</th>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000002</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000003</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000004</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000005</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.9794</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000246</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000247</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000248</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000249</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000250</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2000001  2000002  2000003  2000004  2000005  2000006  2000007  \\\n",
       "2000001   0.9698   0.0005   0.0003   0.0004   0.0002   0.0011   0.0008   \n",
       "2000002   0.0002   0.9760   0.0013   0.0007   0.0003   0.0006   0.0001   \n",
       "2000003   0.0002   0.0016   0.9723   0.0006   0.0003   0.0008   0.0001   \n",
       "2000004   0.0005   0.0025   0.0013   0.9756   0.0001   0.0025   0.0002   \n",
       "2000005   0.0004   0.0013   0.0011   0.0002   0.9794   0.0013   0.0007   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "2000246   0.0008   0.0001   0.0003   0.0001   0.0001   0.0005   0.0004   \n",
       "2000247   0.0000   0.0001   0.0000   0.0000   0.0000   0.0000   0.0000   \n",
       "2000248   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   \n",
       "2000249   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   \n",
       "2000250   0.0001   0.0027   0.0004   0.0001   0.0001   0.0001   0.0000   \n",
       "\n",
       "         2000008  2000009  2000010  ...  2000241  2000242  2000243  2000244  \\\n",
       "2000001   0.0007   0.0005   0.0018  ...   0.0001   0.0002   0.0007   0.0003   \n",
       "2000002   0.0010   0.0012   0.0009  ...   0.0002   0.0001   0.0004   0.0043   \n",
       "2000003   0.0009   0.0008   0.0016  ...   0.0001   0.0000   0.0012   0.0021   \n",
       "2000004   0.0007   0.0008   0.0007  ...   0.0001   0.0000   0.0009   0.0012   \n",
       "2000005   0.0005   0.0013   0.0011  ...   0.0002   0.0002   0.0003   0.0007   \n",
       "...          ...      ...      ...  ...      ...      ...      ...      ...   \n",
       "2000246   0.0001   0.0001   0.0002  ...   0.0000   0.0007   0.0008   0.0005   \n",
       "2000247   0.0000   0.0000   0.0000  ...   0.0001   0.0000   0.0001   0.0012   \n",
       "2000248   0.0000   0.0000   0.0000  ...   0.0001   0.0000   0.0000   0.0002   \n",
       "2000249   0.0000   0.0000   0.0000  ...   0.0002   0.0000   0.0000   0.0001   \n",
       "2000250   0.0015   0.0015   0.0017  ...   0.0018   0.0001   0.0003   0.0056   \n",
       "\n",
       "         2000245  2000246  2000247  2000248  2000249  2000250  \n",
       "2000001   0.0000   0.0065   0.0001   0.0000   0.0000   0.0001  \n",
       "2000002   0.0001   0.0003   0.0001   0.0000   0.0000   0.0009  \n",
       "2000003   0.0000   0.0012   0.0000   0.0000   0.0000   0.0002  \n",
       "2000004   0.0000   0.0009   0.0000   0.0000   0.0000   0.0001  \n",
       "2000005   0.0000   0.0008   0.0000   0.0000   0.0000   0.0002  \n",
       "...          ...      ...      ...      ...      ...      ...  \n",
       "2000246   0.0000   0.9868   0.0001   0.0000   0.0000   0.0000  \n",
       "2000247   0.0012   0.0000   0.9849   0.0009   0.0000   0.0000  \n",
       "2000248   0.0022   0.0000   0.0037   0.9727   0.0015   0.0000  \n",
       "2000249   0.0028   0.0000   0.0005   0.0038   0.9622   0.0000  \n",
       "2000250   0.0002   0.0002   0.0001   0.0000   0.0000   0.9707  \n",
       "\n",
       "[250 rows x 250 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shahafs_pickle[('no_work', 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_250 = shahafs_pickle[('no_work', 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapper between 250 regions to the counties:\n",
    "mapper_250_county = final_mapping[~final_mapping[['cell_id', 'county_id']].duplicated()][['cell_id', 'county_id']].sort_values(by= 'cell_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary that holds: for each county, what regions are mapped to it:\n",
    "df_to_dict = mapper_250_county.pivot(index= 'cell_id', columns= 'county_id', values= 'cell_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to perform the operation of dictionary creation - taking the pivoted df and iterates on each column\n",
    "# This function isn't in the main function (as it should be applied only once)\n",
    "def mapper_250_county_to_dictionary(df):\n",
    "    dict_county_250 = {}\n",
    "    for column in df.columns:\n",
    "        dict_county_250[column] = list(df[df[column].isna() == False][column].values)\n",
    "    return dict_county_250\n",
    "        \n",
    "dict_county_250 = mapper_250_county_to_dictionary(df_to_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Initializing an empty DataFrame to fill along the way - size: 30X30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_empty_df(final_mapping):\n",
    "    initial_df_30 = pd.DataFrame(index= sorted(set(final_mapping['county_id'])), columns= sorted((set(final_mapping['county_id']))))\n",
    "    return initial_df_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the values of the diagonal of the *initial DataFrame!*\n",
    "# First function is ment only to turn 'initial_df_30' to be global, so the inner function will be able to use it without\n",
    "# actually receive it as input\n",
    "def update_diagonal(merged, x):\n",
    "    global initial_df_30\n",
    "    initial_df_30 = x\n",
    "    \n",
    "    # This function updates the values of the diagonal of the *initial DataFrame!* (== 'initial_df_30')\n",
    "    def update_diagonal_2(df):\n",
    "        diagonal_value = df.loc[ : , list(df['index'])].to_numpy().sum()           # Slicing the df to get the relevant matrix, then summing on all of it\n",
    "        initial_df_30.loc[df['county_id'].iloc[0], df['county_id'].iloc[0]] = diagonal_value    # inserting the value in the right place in the matrix     \n",
    "\n",
    "    merged.groupby(by= 'county_id').apply(update_diagonal_2)    # Activating the function here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Now, we'd like to update the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rows(df, initial_df_30, dict_county_250):                   \n",
    "    df.set_index('index', inplace= True)    # Setting the index column back to be the index of the merged DataFrame\n",
    "    for i in range(30):                 # iterating on the initial df to update it. it has 30 rows and columns (as amount of counties)\n",
    "        for j in range(30):\n",
    "            if i == j:           # We already considered this case when filling the diagonal of the initial matrix\n",
    "                continue\n",
    "                \n",
    "            else:                 # Creating a DF that holds the travels from regions i (one county) to regions j (another county)\n",
    "                specific_cell_value = df.loc[list(dict_county_250.values())[i] , list(dict_county_250.values())[j]].to_numpy().sum()     # Choosing the relevant rows and columns\n",
    "                initial_df_30.loc[list(dict_county_250.keys())[i] , list(dict_county_250.keys())[j]] = specific_cell_value            # Update the value of the cell in the right place in the initial df\n",
    "#update_rows(merged)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Normalizing the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the rows to be summed to 1:\n",
    "def normalizing_rows(final_df):\n",
    "    final_df.iloc[:,:] = Normalizer(norm= 'l1').fit_transform(final_df)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> THE MAIN FUNCTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df_250, final_mapping, mapper_250_county, dict_county_250):\n",
    "    df_250 = df_250.copy()\n",
    "    initial_df_30 = initialize_empty_df(final_mapping)      # Initializing an empty DataFrame to fill along the way - size: 30X30\n",
    "    df_250.reset_index(inplace= True)\n",
    "    \n",
    "    # Merging between the whole df and the mapper\n",
    "    merged = df_250.merge(mapper_250_county, left_on= 'index', right_on= 'cell_id').drop('cell_id', axis= 1)\n",
    "    \n",
    "    # Update the values of the diagonal of the *initial DataFrame!* (== 'initial_df_30')\n",
    "    update_diagonal(merged, initial_df_30)\n",
    "    #merged.groupby(by= 'county_id').apply(update_diagonal(initial_df_30))\n",
    "    \n",
    "    # Update the values of the rows (without the diagonal) of the *initial DataFrame!* (== 'initial_df_30')\n",
    "    update_rows(merged, initial_df_30, dict_county_250)  \n",
    "    \n",
    "    # Normalizing the rows to be summed to 1:\n",
    "    final_df = normalizing_rows(initial_df_30.copy())\n",
    "    \n",
    "    return final_df     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_configuration_test  = main(shahafs_pickle[('no_work', 0)], final_mapping, mapper_250_county, dict_county_250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final dictionary to output\n",
    "final_dict_to_pickle = {}\n",
    "for key in shahafs_pickle.keys():\n",
    "    final_dict_to_pickle[key] = main(shahafs_pickle[key], final_mapping, mapper_250_county, dict_county_250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mat_macro_model_df_30.pickle', 'wb') as handle:\n",
    "    pickle.dump(final_dict_to_pickle, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mat_macro_model_df_30.pickle', 'rb') as handle:\n",
    "    yotams_pickle = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
